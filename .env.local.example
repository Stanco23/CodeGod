# Code-God Configuration for Local-First Deployment
# Copy this file to .env for fully local deployment with NO API KEYS REQUIRED

# ===================================
# Model Configuration (LOCAL FIRST)
# ===================================

# Prefer local models over API models
PREFER_LOCAL=true

# Master AI Model Selection
# Options:
#   - auto: Automatically select best available local model
#   - llama3.1:70b: Meta Llama 3.1 70B (recommended, 40GB VRAM)
#   - llama3.1:405b: Meta Llama 3.1 405B (best quality, 200GB+ VRAM)
#   - qwen2.5:72b: Qwen 2.5 72B (excellent, 40GB VRAM)
#   - mixtral:8x7b: Mixtral 8x7B (good, 26GB VRAM)
#   - deepseek-coder:33b: DeepSeek Coder 33B (code-focused, 20GB VRAM)
#   - claude-sonnet-4.5: Use API (requires ANTHROPIC_API_KEY)
#   - gpt-4-turbo-preview: Use API (requires OPENAI_API_KEY)
MASTER_MODEL=llama3.1:70b

# Worker Model Selection (small models for efficiency)
# Options:
#   - phi-3:3b: Microsoft Phi-3 3B (fast, 2GB VRAM)
#   - llama-3.2:3b: Meta Llama 3.2 3B (balanced, 2GB VRAM)
#   - qwen2.5:3b: Qwen 2.5 3B (good quality, 2GB VRAM)
#   - mistral:7b: Mistral 7B (better quality, 4GB VRAM)
#   - codellama:7b: Code Llama 7B (code-focused, 4GB VRAM)
WORKER_MODEL=phi-3:3b

# ===================================
# API Keys (OPTIONAL - Only if using API models)
# ===================================

# Only needed if MASTER_MODEL is set to claude-* or gpt-*
# Leave empty for fully local deployment
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# ===================================
# System Configuration
# ===================================

# Maximum number of tasks to run in parallel
# Adjust based on your GPU/CPU capacity
MAX_PARALLEL_TASKS=5

# Task execution timeout (seconds)
TASK_TIMEOUT=300

# ===================================
# Worker Configuration
# ===================================

# Number of worker replicas per type
# Reduce if running on limited hardware
WORKER_BACKEND_REPLICAS=2
WORKER_FRONTEND_REPLICAS=2
WORKER_TESTING_REPLICAS=1
WORKER_DEVOPS_REPLICAS=1

# ===================================
# Infrastructure
# ===================================

# ChromaDB (Vector Database)
CHROMADB_HOST=chromadb
CHROMADB_PORT=8000

# Redis (Task Queue)
REDIS_HOST=redis
REDIS_PORT=6379

# PostgreSQL (Structured Data)
POSTGRES_DB=codegod
POSTGRES_USER=codegod
POSTGRES_PASSWORD=changeme
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# ===================================
# MCP Server Configuration (OPTIONAL)
# ===================================

# GitHub MCP Server (optional, for GitHub operations)
GITHUB_PERSONAL_ACCESS_TOKEN=

# PostgreSQL Connection for MCP Server
POSTGRES_CONNECTION_STRING=postgresql://codegod:changeme@postgres:5432/codegod

# Brave Search API (optional, for web search)
BRAVE_API_KEY=

# Google Maps API (optional, for location services)
GOOGLE_MAPS_API_KEY=

# Slack Integration (optional)
SLACK_BOT_TOKEN=
SLACK_TEAM_ID=

# ===================================
# Logging
# ===================================

LOG_LEVEL=INFO

# ===================================
# Monitoring (Optional)
# ===================================

# Grafana admin password
GRAFANA_PASSWORD=admin

# Prometheus retention
PROMETHEUS_RETENTION=15d

# ===================================
# Deployment
# ===================================

# Environment: development, staging, production
ENVIRONMENT=development

# External domain (for production)
DOMAIN=localhost

# SSL/TLS (for production)
SSL_ENABLED=false
SSL_CERT_PATH=
SSL_KEY_PATH=

# ===================================
# Hardware Recommendations
# ===================================

# MINIMAL (Master: llama3.1:70b, Workers: phi-3:3b):
#   - 48GB RAM
#   - 40GB VRAM (GPU) or 64GB RAM (CPU only)
#   - 8 CPU cores
#   - 100GB SSD storage

# RECOMMENDED (Master: qwen2.5:72b, Workers: mistral:7b):
#   - 64GB RAM
#   - 48GB VRAM (GPU) or 96GB RAM (CPU only)
#   - 16 CPU cores
#   - 200GB SSD storage

# HIGH-END (Master: llama3.1:405b, Workers: codellama:7b):
#   - 256GB RAM
#   - 200GB VRAM (multi-GPU) or 512GB RAM (CPU only)
#   - 32 CPU cores
#   - 500GB NVMe storage

# CPU-ONLY (Master: mixtral:8x7b, Workers: phi-3:3b):
#   - 96GB RAM
#   - 16 CPU cores
#   - 200GB SSD storage
#   - Note: Will be significantly slower than GPU
