# Code-God Environment Configuration
# Copy this file to .env and configure as needed

# ============================================
# MODEL CONFIGURATION
# ============================================

# Prefer local models over API (default: true)
PREFER_LOCAL=true

# Master AI Model Selection
# Options:
#   - "auto" (default) - Auto-select best available model
#   - Specific local model name (e.g., "llama3.1:70b", "qwen2.5:1.5b")
#   - API model name (e.g., "claude-sonnet-4.5", "gpt-4-turbo-preview")
MASTER_MODEL=auto

# ============================================
# SMALL MODELS (1B-3B) - For testing/low resource
# ============================================
# Uncomment one of these for small model usage:

# MASTER_MODEL=qwen2.5:1.5b          # Qwen 2.5 1.5B (fastest, ~1GB RAM)
# MASTER_MODEL=qwen2.5:3b            # Qwen 2.5 3B (~2GB RAM)
# MASTER_MODEL=llama3.2:1b           # Llama 3.2 1B
# MASTER_MODEL=llama3.2:3b           # Llama 3.2 3B
# MASTER_MODEL=phi3:mini             # Microsoft Phi-3 Mini 3.8B
# MASTER_MODEL=gemma2:2b             # Google Gemma 2 2B

# ============================================
# MEDIUM MODELS (7B-13B) - Balanced
# ============================================
# MASTER_MODEL=llama3.1:8b           # Llama 3.1 8B
# MASTER_MODEL=mistral:7b            # Mistral 7B
# MASTER_MODEL=qwen2.5:7b            # Qwen 2.5 7B
# MASTER_MODEL=deepseek-coder:6.7b   # DeepSeek Coder 6.7B (code-focused)

# ============================================
# LARGE MODELS (70B+) - Best quality
# ============================================
# MASTER_MODEL=llama3.1:70b          # Llama 3.1 70B (recommended)
# MASTER_MODEL=qwen2.5:72b           # Qwen 2.5 72B
# MASTER_MODEL=mixtral:8x7b          # Mixtral 8x7B
# MASTER_MODEL=llama3.1:405b         # Llama 3.1 405B (requires massive GPU)

# ============================================
# API MODELS (Optional - only if you want API)
# ============================================
# Get from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-api03-...

# Get from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...

# When using API models:
# PREFER_LOCAL=false
# MASTER_MODEL=claude-sonnet-4.5
# or
# MASTER_MODEL=gpt-4-turbo-preview

# ============================================
# WORKER MODELS (Future)
# ============================================
# For multi-agent workers (not yet implemented)
# WORKER_MODEL=qwen2.5:3b
# WORKER_COUNT=3

# ============================================
# CONVERSATION SETTINGS
# ============================================
# Maximum conversation history to maintain (default: 10)
# MAX_HISTORY=10

# ============================================
# MCP SETTINGS
# ============================================
# Directory for MCP servers (default: ~/.codegod/mcp_servers)
# MCP_SERVERS_DIR=/custom/path/to/mcp_servers
